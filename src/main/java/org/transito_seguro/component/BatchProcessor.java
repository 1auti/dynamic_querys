package org.transito_seguro.component;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Lazy;
import org.springframework.stereotype.Component;
import org.transito_seguro.dto.ParametrosFiltrosDTO;
import org.transito_seguro.enums.EstrategiaPaginacion;
import org.transito_seguro.enums.EstrategiaProcessing;
import org.transito_seguro.enums.TipoConsolidacion;
import org.transito_seguro.model.EstimacionDataset;
import org.transito_seguro.model.query.QueryStorage;
import org.transito_seguro.model.ContextoProcesamiento;
import org.transito_seguro.repository.QueryStorageRepository;
import org.transito_seguro.repository.impl.InfraccionesRepositoryImpl;
import org.transito_seguro.service.QueryRegistryService;
import org.transito_seguro.utils.LogFileWriter;

import javax.annotation.PreDestroy;
import java.math.BigDecimal;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.function.Consumer;
import java.util.stream.Collectors;

@Slf4j
@Component
public class BatchProcessor {

    @Value("${app.batch.size:5000}")
    private int defaultBatchSize;

    @Value("${app.batch.memory-critical-threshold:0.85}")
    private double memoryCriticalThreshold;

    @Value("${app.batch.parallel-threshold-per-province:50000}")
    private int parallelThresholdPerProvince;

    @Value("${app.batch.parallel-threshold-total:300000}")
    private int parallelThresholdTotal;

    @Value("${app.batch.massive-threshold-per-province:200000}")
    private int massiveThresholdPerProvince;

    @Value("${app.batch.max-parallel-provinces:6}")
    private int maxParallelProvinces;

    @Value("${app.batch.thread-pool-size:6}")
    private int threadPoolSize;

    @Value("${consolidacion.agregacion.umbral-error:10}")
    private int umbralErrorEstimacion;

    @Value("${consolidacion.agregacion.limite-validacion:10000}")
    private int limiteValidacion;

    @Value("${consolidacion.agregacion.limite-absoluto:100000}")
    private int limiteAbsoluto;

    @Autowired
    private QueryRegistryService queryRegistryService;;

    @Autowired
    private LogFileWriter logFileWriter;

    private ExecutorService parallelExecutor;
    private final Map<String, Object[]> lastKeyPerProvince = new ConcurrentHashMap<>();
    private final AtomicInteger totalRegistrosGlobales = new AtomicInteger(0);
    private final Map<String, Integer> contadoresPorProvincia = new ConcurrentHashMap<>();
    private final AtomicLong ultimoHeartbeat = new AtomicLong(0);
    private final Map<String, Boolean> cacheQueryConsolidable = new ConcurrentHashMap<>();
    private final AtomicInteger cambiosEstrategiaPorOOM = new AtomicInteger(0);

    private static final long HEARTBEAT_INTERVAL_MS = 30000;

    private long tiempoInicioGlobal;

    @Autowired
    private QueryStorageRepository queryStorageRepository;

    @Autowired
    public void init() {
        this.parallelExecutor = new ThreadPoolExecutor(
                threadPoolSize,
                threadPoolSize,
                60L,
                TimeUnit.SECONDS,
                new LinkedBlockingQueue<>(100),
                new ThreadPoolExecutor.CallerRunsPolicy());
    }

    @PreDestroy
    public void shutdown() {
        log.info("Cerrando BatchProcessor...");

        // 1. CERRAR EXECUTOR
        if (parallelExecutor != null && !parallelExecutor.isShutdown()) {
            parallelExecutor.shutdown();
            try {
                if (!parallelExecutor.awaitTermination(60, TimeUnit.SECONDS)) {
                    log.warn("â±ï¸ Executor no terminÃ³ en 60s, forzando shutdown");
                    parallelExecutor.shutdownNow();

                    // Dar 30s mÃ¡s para terminar forzadamente
                    if (!parallelExecutor.awaitTermination(30, TimeUnit.SECONDS)) {
                        log.error("âŒ Executor no se pudo cerrar completamente");
                    }
                } else {
                    log.info("âœ… Executor cerrado correctamente");
                }
            } catch (InterruptedException e) {
                log.warn("âš ï¸ Shutdown interrumpido, forzando cierre");
                parallelExecutor.shutdownNow();
                Thread.currentThread().interrupt();
            }
        }

        // 2. LIMPIAR CACHES
        cacheQueryConsolidable.clear();

        // 3. REPORTAR MÃ‰TRICAS (SIEMPRE, al final)
        reportarMetricasFinales();

        log.info("âœ… BatchProcessor cerrado completamente");
    }

    /**
     * ğŸ“Š Reporta mÃ©tricas finales del ciclo de vida del BatchProcessor.
     * Se llama al final del shutdown, SIEMPRE.
     */
    private void reportarMetricasFinales() {
        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log.info("ğŸ“Š MÃ‰TRICAS FINALES DE BATCHPROCESSOR");
        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

        // Cambios de estrategia por OOM
        int cambios = cambiosEstrategiaPorOOM.get();
        if (cambios > 0) {
            log.warn("âš ï¸ Cambios de estrategia AGREGACIONâ†’CRUDO: {}", cambios);
            log.info("ğŸ’¡ RecomendaciÃ³n: Revisar queries con GROUP BY para mejorar estimaciones");
            log.info("   - Ejecutar ANALYZE en las tablas");
            log.info("   - Revisar cardinalidad de campos en GROUP BY");
            log.info("   - Considerar pre-agregar datos en vistas materializadas");
        } else {
            log.info("âœ… Sin cambios de estrategia por OOM detectados");
        }

        // Total de registros procesados globalmente
        int totalRegistros = totalRegistrosGlobales.get();
        if (totalRegistros > 0) {
            log.info("ğŸ“ˆ Total de registros procesados: {}", totalRegistros);
        }

        // Provincias procesadas
        if (!contadoresPorProvincia.isEmpty()) {
            log.info("ğŸ—ºï¸ Provincias procesadas: {}", contadoresPorProvincia.size());

            // Top 5 provincias con mÃ¡s registros
            List<Map.Entry<String, Integer>> top5 = contadoresPorProvincia.entrySet().stream()
                    .sorted(Map.Entry.<String, Integer>comparingByValue().reversed())
                    .limit(5)
                    .collect(Collectors.toList());

            if (!top5.isEmpty()) {
                log.info("ğŸ“Š Top 5 provincias por volumen:");
                for (int i = 0; i < top5.size(); i++) {
                    Map.Entry<String, Integer> entry = top5.get(i);
                    log.info("   {}. {}: {} registros",
                            i + 1, entry.getKey(), entry.getValue());
                }
            }
        }

        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    }

    public void procesarEnLotes(
            List<InfraccionesRepositoryImpl> repositories,
            ParametrosFiltrosDTO filtros,
            String nombreQuery,
            Consumer<List<Map<String, Object>>> procesarLotes) {

        inicializarProcesamiento();
        logInicio(repositories.size(), nombreQuery);

        EstimacionDataset estimacion = estimarDataset(repositories, filtros, nombreQuery);
        logEstimacion(estimacion);

        EstrategiaProcessing estrategia = decidirEstrategia(estimacion);
        log.info("Estrategia seleccionada: {}", estrategia);

        ContextoProcesamiento contexto = new ContextoProcesamiento(procesarLotes, null);

        QueryStorage queryStorage = queryRegistryService.buscarQuery(nombreQuery)
                .orElse(null);

        try {
            switch (estrategia) {
                case PARALELO:
                    procesarParalelo(repositories, filtros, nombreQuery, contexto,queryStorage);
                    break;
                case HIBRIDO:
                    procesarHibrido(repositories, filtros, nombreQuery, contexto,queryStorage);
                    break;
                case SECUENCIAL:
                    procesarSecuencial(repositories, filtros, nombreQuery, contexto);
                    break;
            }
        } finally {
            imprimirResumenFinal();
        }
    }

    private void inicializarProcesamiento() {
        tiempoInicioGlobal = System.currentTimeMillis();
        ultimoHeartbeat.set(tiempoInicioGlobal);
        totalRegistrosGlobales.set(0);
        contadoresPorProvincia.clear();
    }

    private void logInicio(int numProvincias, String nombreQuery) {
        if (!log.isInfoEnabled())
            return;

        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log.info("Inicio procesamiento - Provincias: {} | Query: {} | Memoria: {:.1f}%",
                numProvincias, nombreQuery, obtenerPorcentajeMemoriaUsada());
        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    }

    private void logEstimacion(EstimacionDataset estimacion) {
        if (!log.isInfoEnabled())
            return;

        log.info("EstimaciÃ³n - Total: {} | Promedio: {} reg/prov | MÃ¡ximo: {}",
                estimacion.getTotalEstimado(),
                (int) estimacion.getPromedioPorProvincia(),
                estimacion.getMaximoPorProvincia());
    }

    private void imprimirResumenFinal() {
        if (!log.isInfoEnabled())
            return;

        long duracionTotal = System.currentTimeMillis() - tiempoInicioGlobal;
        int total = totalRegistrosGlobales.get();

        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log.info("Completado - DuraciÃ³n: {}s | Total: {} registros | Velocidad: {} reg/s | Memoria: {:.1f}%",
                duracionTotal / 1000,
                total,
                total * 1000 / Math.max(duracionTotal, 1),
                obtenerPorcentajeMemoriaUsada());
        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    }

    /**
     * Estima el tamaÃ±o del dataset usando COUNT(*) en lugar de cargar datos.
     *
     * @param repositories Lista de repositorios (uno por provincia)
     * @param filtros      Filtros aplicados (fechas, tipos, etc.)
     * @param nombreQuery  CÃ³digo de la query a ejecutar
     * @return EstimaciÃ³n con total real, promedio y mÃ¡ximo por provincia
     */
    private EstimacionDataset estimarDataset(
            List<InfraccionesRepositoryImpl> repositories,
            ParametrosFiltrosDTO filtros,
            String nombreQuery) {

        // Ejecutar COUNT(*) en paralelo para todas las provincias
        List<Integer> conteos = repositories.parallelStream()
                .map(repo -> obtenerConteoReal(repo, nombreQuery, filtros))
                .collect(Collectors.toList());

        // Calcular estadÃ­sticas
        int totalEstimado = conteos.stream().mapToInt(Integer::intValue).sum();
        double promedio = repositories.isEmpty() ? 0 : (double) totalEstimado / repositories.size();
        int maximo = conteos.stream().mapToInt(Integer::intValue).max().orElse(0);

        return new EstimacionDataset(totalEstimado, promedio, maximo);
    }

/*
 * Obtiene el conteo real de registros usando COUNT(*) O estimaciÃ³n del anÃ¡lisis.
 * Si el QueryAnalyzer ya proporcionÃ³ una estimaciÃ³n confiable, la usa.
 *
 * @param repo        Repositorio de la provincia
 * @param nombreQuery CÃ³digo de la query
 * @param filtros     Filtros aplicados
 * @return NÃºmero exacto o estimado de registros
 */
private int obtenerConteoReal(
        InfraccionesRepositoryImpl repo,
        String nombreQuery,
        ParametrosFiltrosDTO filtros) {
    try {
        Optional<QueryStorage> queryOpt = queryRegistryService.buscarQuery(nombreQuery);
        if (!queryOpt.isPresent()) {
            log.warn("Query no encontrada: {} para provincia {}", nombreQuery, repo.getProvincia());
            return 0;
        }

        QueryStorage queryStorage = queryOpt.get();

        /**
         * ES mejor usar el count real porque es maala idea a la larga no estimar la cantidad de registros
         * que podes tener :)
         */

        String queryOriginal = queryStorage.getSqlQuery();
        String queryConteo = construirQueryConteo(queryOriginal);
        Integer conteoReal = repo.ejecutarQueryConteo(queryConteo, filtros);

        log.info("ğŸ” Conteo REAL para {}: {} registros (estimaciÃ³n previa: {})",
                 repo.getProvincia(),
                 conteoReal,
                 queryStorage.getRegistrosEstimados());

        return conteoReal != null ? conteoReal : 0;

    } catch (Exception e) {
        log.error("Error obteniendo conteo para {} - {}: {}",
                repo.getProvincia(), nombreQuery, e.getMessage());
        return 0;
    }
}

    /**
     * Envuelve la query original en un SELECT COUNT(*).
     *
     * @param queryOriginal Query SQL original
     * @return Query modificada para contar registros
     */
    /**
     * Construye query de conteo removiendo ORDER BY y LIMIT.
     *
     * MEJORADO: Remueve LIMIT de cualquier formato usando substring
     * para evitar problemas con expresiones complejas.
     *
     * @param queryOriginal Query SQL original
     * @return Query envuelta en SELECT COUNT(*)
     */
    /**
     *  Regex mejorado que funciona con funciones.
     */
    private String construirQueryConteo(String queryOriginal) {
        if (queryOriginal == null || queryOriginal.trim().isEmpty()) {
            throw new IllegalArgumentException("Query original no puede estar vacÃ­a");
        }

        String queryLimpia = queryOriginal.trim();

        // 1. Remover ; final
        queryLimpia = queryLimpia.replaceAll(";\\s*$", "");

        // 2. Remover ORDER BY hasta el final
        queryLimpia = queryLimpia.replaceAll("(?i)\\s+ORDER\\s+BY[^;]*$", "");

        // 3. âœ… CRÃTICO: Remover LIMIT con CUALQUIER contenido hasta el final
        //    Este regex captura desde LIMIT hasta el fin, incluyendo funciones
        queryLimpia = queryLimpia.replaceAll("(?i)\\s+LIMIT\\s+[^;]*$", "");

        // 4. Remover OFFSET si queda
        queryLimpia = queryLimpia.replaceAll("(?i)\\s+OFFSET\\s+[^;]*$", "");

        // 5. Envolver en COUNT(*)
        String queryConteo = String.format("SELECT COUNT(*) as total FROM (%s) AS subquery", queryLimpia.trim());

        log.debug("âœ… Query conteo: {} chars", queryConteo.length());

        return queryConteo;
    }

    private EstrategiaProcessing decidirEstrategia(EstimacionDataset estimacion) {
        if (estimacion.getPromedioPorProvincia() < parallelThresholdPerProvince &&
                estimacion.getTotalEstimado() < parallelThresholdTotal) {
            return EstrategiaProcessing.PARALELO;
        }
        if (estimacion.getMaximoPorProvincia() > massiveThresholdPerProvince) {
            return EstrategiaProcessing.SECUENCIAL;
        }
        return EstrategiaProcessing.HIBRIDO;
    }

    /**
     * VERSIÃ“N MEJORADA con monitoreo de progreso
     */
    private void procesarParalelo(
            List<InfraccionesRepositoryImpl> repositories,
            ParametrosFiltrosDTO filtros,
            String nombreQuery,
            ContextoProcesamiento contexto,
            QueryStorage queryStorage) {

        log.info("ğŸš€ Ejecutando modo PARALELO - {} provincias simultÃ¡neas", repositories.size());

        // âœ… Contadores atÃ³micos para seguimiento en tiempo real
        AtomicInteger provinciasCompletadas = new AtomicInteger(0);
        AtomicInteger provinciasEnProceso = new AtomicInteger(0);
        Map<String, String> estadoPorProvincia = new ConcurrentHashMap<>();

        // âœ… Thread de monitoreo en background
        ScheduledExecutorService monitor = Executors.newSingleThreadScheduledExecutor();
        ScheduledFuture<?> tareaMonitoreo = monitor.scheduleAtFixedRate(() -> {
            reportarProgresoParalelo(
                    repositories.size(),
                    provinciasCompletadas.get(),
                    provinciasEnProceso.get(),
                    estadoPorProvincia
            );
        }, 2, 3, TimeUnit.SECONDS); // Reporta cada 3 segundos

        try {
            // Crear futures con seguimiento individual
            List<CompletableFuture<Void>> futures = repositories.stream()
                    .map(repo -> CompletableFuture.runAsync(() -> {
                        String provincia = repo.getProvincia();

                        try {
                            // âœ… Marcar inicio
                            provinciasEnProceso.incrementAndGet();
                            estadoPorProvincia.put(provincia, "ğŸ”„ PROCESANDO");
                            log.info("â–¶ï¸  Iniciando procesamiento de {}", provincia);

                            // Ejecutar provincia
                            ejecutarProvincia(repo, filtros, nombreQuery, contexto, queryStorage);

                            // âœ… Marcar completado
                            estadoPorProvincia.put(provincia, "âœ… COMPLETADO");
                            int completadas = provinciasCompletadas.incrementAndGet();
                            provinciasEnProceso.decrementAndGet();

                            log.info("âœ… {} completada ({}/{})",
                                    provincia, completadas, repositories.size());

                        } catch (Exception e) {
                            estadoPorProvincia.put(provincia, "âŒ ERROR: " + e.getMessage());
                            provinciasEnProceso.decrementAndGet();
                            log.error("âŒ Error en {}: {}", provincia, e.getMessage(), e);
                        }

                    }, parallelExecutor))
                    .collect(Collectors.toList());

            // Esperar a que todas terminen
            CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();

        } finally {
            // âœ… Detener monitoreo
            tareaMonitoreo.cancel(false);
            monitor.shutdown();

            // âœ… Reporte final
            log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
            log.info(" PROCESAMIENTO PARALELO COMPLETADO");
            log.info("   Total: {}/{} provincias",
                    provinciasCompletadas.get(), repositories.size());
            log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

            contexto.procesarTodosResultados();
        }
    }

    /**
     * ğŸ“Š Reporta progreso cada N segundos
     */
    private void reportarProgresoParalelo(
            int total,
            int completadas,
            int enProceso,
            Map<String, String> estados) {

        if (completadas >= total) {
            return; // Ya terminÃ³
        }

        double progreso = (double) completadas / total * 100;
        int registrosActuales = totalRegistrosGlobales.get();

        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log.info("ğŸ“Š PROGRESO PARALELO: {}/{} provincias ({:.1f}%)",
                completadas, total, progreso);
        log.info("   En proceso: {} | Registros: {} | Memoria: {:.1f}%",
                enProceso, registrosActuales, obtenerPorcentajeMemoriaUsada());

        // Mostrar estado detallado
        estados.entrySet().stream()
                .sorted(Map.Entry.comparingByKey())
                .forEach(entry ->
                        log.info("   {} - {}", entry.getKey(), entry.getValue())
                );

        log.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    }

    private void procesarHibrido(
            List<InfraccionesRepositoryImpl> repositories,
            ParametrosFiltrosDTO filtros,
            String nombreQuery,
            ContextoProcesamiento contexto,
            QueryStorage queryStorage) {

        log.info("Ejecutando modo HÃBRIDO");

        for (int i = 0; i < repositories.size(); i += maxParallelProvinces) {
            int endIndex = Math.min(i + maxParallelProvinces, repositories.size());
            List<InfraccionesRepositoryImpl> grupo = repositories.subList(i, endIndex);

            List<CompletableFuture<Void>> futures = grupo.stream()
                    .map(repo -> CompletableFuture.runAsync(
                            () -> ejecutarProvincia(repo, filtros, nombreQuery, contexto,queryStorage),
                            parallelExecutor))
                    .collect(Collectors.toList());

            CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();
            contexto.procesarTodosResultados();

            if (endIndex < repositories.size() && esMemoriaAlta()) {
                pausarSiNecesario();
            }
        }
    }

    private void procesarSecuencial(
            List<InfraccionesRepositoryImpl> repositories,
            ParametrosFiltrosDTO filtros,
            String nombreQuery,
            ContextoProcesamiento contexto) {

        int batchSize = calcularTamanoLoteOptimo(filtros);

        for (int i = 0; i < repositories.size(); i++) {
            InfraccionesRepositoryImpl repo = repositories.get(i);

            logHeartbeat(repositories.size());
            procesarProvinciaSecuencial(repo, filtros, nombreQuery, contexto, batchSize);
            contexto.procesarTodosResultados();

            if (i < repositories.size() - 1 && esMemoriaAlta()) {
                pausarSiNecesario();
            }
        }
    }

    private void procesarProvinciaSecuencial(
            InfraccionesRepositoryImpl repo,
            ParametrosFiltrosDTO filtros,
            String nombreQuery,
            ContextoProcesamiento contexto,
            int batchSize) {

        String provincia = repo.getProvincia();
        lastKeyPerProvince.remove(provincia);

        int procesados = 0;
        int offset = 0;
        boolean continuar = true;

        while (continuar) {
            try {
                if (esMemoriaCritica()) {
                    batchSize = Math.max(500, batchSize / 2);
                }

                ParametrosFiltrosDTO filtrosLote = crearFiltrosParaLote(filtros, batchSize, offset, provincia);
                List<Map<String, Object>> lote = repo.ejecutarQueryConFiltros(nombreQuery, filtrosLote);

                if (lote == null || lote.isEmpty()) {
                    break;
                }

                guardarLastKey(lote, provincia);

                List<Map<String, Object>> loteInmutable = crearCopiasInmutables(lote, provincia);
                contexto.agregarResultados(loteInmutable);

                procesados += lote.size();
                offset += batchSize;
                continuar = lote.size() >= batchSize;

            } catch (OutOfMemoryError oom) {
                log.error("OOM en {}", provincia);
                pausarSiNecesario();
                break;
            } catch (Exception e) {
                log.error("Error en {}: {}", provincia, e.getMessage());
                break;
            }
        }

        actualizarContadores(provincia, procesados);
        lastKeyPerProvince.remove(provincia);
    }

   /**
 * Ejecuta una provincia decidiendo la estrategia segÃºn el tipo de query.
 *
 * @param repo Repositorio de la provincia
 * @param filtros Filtros aplicados
 * @param nombreQuery CÃ³digo de la query
 * @param contexto Contexto de procesamiento
 */
private void ejecutarProvincia(
        InfraccionesRepositoryImpl repo,
        ParametrosFiltrosDTO filtros,
        String nombreQuery,
        ContextoProcesamiento contexto,
        QueryStorage queryStorage) {

    String provincia = repo.getProvincia();


    // Verificar si debe forzar paginaciÃ³n (override manual)
      boolean estrategiaSinPaginacion = queryStorage.getEstrategiaPaginacion() == EstrategiaPaginacion.SIN_PAGINACION;

     // Si la query no es consolidable, siempre usar paginaciÃ³n
    if (estrategiaSinPaginacion && esQueryConsolidable(nombreQuery)) {

        // Decidir estrategia segÃºn tipo de consolidaciÃ³n
        if (queryStorage.getTipoConsolidacion() == TipoConsolidacion.AGREGACION) {
            // Query bien diseÃ±ada (GROUP BY con pocos registros): carga directa
            ejecutarQueryConsolidableAgregacion(repo, filtros, nombreQuery, provincia, contexto, queryStorage);

        } else if (queryStorage.getTipoConsolidacion() == TipoConsolidacion.CRUDO) {
            // Query mal diseÃ±ada (sin GROUP BY o muchos registros): streaming
            ejecutarQueryConsolidableCrudo(repo, filtros, nombreQuery, provincia, contexto, queryStorage);

        } else if (queryStorage.getTipoConsolidacion() == TipoConsolidacion.DEDUPLICACION) {
            // Query con deduplicaciÃ³n: carga directa si < 10K, sino streaming
            if (queryStorage.getRegistrosEstimados() != null && queryStorage.getRegistrosEstimados() < 10000) {
                ejecutarQueryConsolidableAgregacion(repo, filtros, nombreQuery, provincia, contexto, queryStorage);
            } else {
                ejecutarQueryConsolidableCrudo(repo, filtros, nombreQuery, provincia, contexto, queryStorage);
            }

        } else {
            // Tipo desconocido, JERARQUICA o COMBINADA: usar estrategia conservadora (streaming)
            log.warn("Tipo de consolidaciÃ³n {} para {}, usando streaming",
                     queryStorage.getTipoConsolidacion(), nombreQuery);
            ejecutarQueryConsolidableCrudo(repo, filtros, nombreQuery, provincia, contexto, queryStorage);
        }
    } else {
        // Query normal: usar paginaciÃ³n estÃ¡ndar
        ejecutarQueryPaginada(repo, filtros, nombreQuery, provincia, contexto);
    }
}

    private boolean esQueryConsolidable(String nombreQuery) {
        return cacheQueryConsolidable.computeIfAbsent(nombreQuery, key -> {
            try {
                Optional<QueryStorage> qs = queryRegistryService.buscarQuery(key);
                return qs.map(QueryStorage::getEsConsolidable).orElse(false);
            } catch (Exception e) {
                return false;
            }
        });
    }


    /**
     * ğŸ›¡ï¸ VERSIÃ“N PROTEGIDA contra OOM
     *
     * Ejecuta query consolidable AGREGACION con validaciÃ³n de tamaÃ±o.
     * Si detecta que el resultado es mucho mayor que lo estimado,
     * cambia automÃ¡ticamente a estrategia CRUDO (streaming).
     */
    private void ejecutarQueryConsolidableAgregacion(
            InfraccionesRepositoryImpl repo,
            ParametrosFiltrosDTO filtros,
            String nombreQuery,
            String provincia,
            ContextoProcesamiento contexto,
            QueryStorage info) {

        try {
            log.debug("ğŸ” Ejecutando query AGREGACION para {}: {} registros estimados",
                    provincia, info.getRegistrosEstimados());

            // ===== CAPA 1: VALIDACIÃ“N PRE-EJECUCIÃ“N =====
            Integer estimacion = info.getRegistrosEstimados();

            if (estimacion == null || estimacion == 0) {
                log.warn("âš ï¸ Sin estimaciÃ³n confiable para query {}, usando estrategia CRUDO por seguridad",
                        nombreQuery);
                ejecutarQueryConsolidableCrudo(repo, filtros, nombreQuery, provincia, contexto, info);
                return;
            }

            // Si la estimaciÃ³n es muy alta, ir directo a CRUDO
            if (estimacion > limiteValidacion) {
                log.info("ğŸ“Š EstimaciÃ³n alta ({} registros), usando estrategia CRUDO directamente",
                        estimacion);
                ejecutarQueryConsolidableCrudo(repo, filtros, nombreQuery, provincia, contexto, info);
                return;
            }

            // ===== CAPA 2: EJECUCIÃ“N CON LÃMITE DE VALIDACIÃ“N =====

            // Crear filtros con lÃ­mite de seguridad para la primera validaciÃ³n
            ParametrosFiltrosDTO filtrosValidacion = filtros.toBuilder()
                    .limite(limiteValidacion)  // LÃ­mite temporal para validar
                    .offset(null)
                    .build();

            log.debug("ğŸ§ª Validando con lÃ­mite de {} registros", limiteValidacion);

            List<Map<String, Object>> muestraValidacion =
                    repo.ejecutarQueryConFiltros(nombreQuery, filtrosValidacion);

            if (muestraValidacion == null) {
                log.warn("âš ï¸ Query retornÃ³ null para {}", provincia);
                return;
            }

            int tamanoMuestra = muestraValidacion.size();

            // ===== CAPA 3: ANÃLISIS Y DECISIÃ“N =====

            // CASO 1: La muestra estÃ¡ incompleta (hay mÃ¡s datos)
            if (tamanoMuestra >= limiteValidacion) {
                log.warn("âš ï¸ Query retornÃ³ {} registros (lÃ­mite de validaciÃ³n alcanzado)", tamanoMuestra);
                log.warn("ğŸ“Š EstimaciÃ³n era {} pero hay al menos {}+ registros", estimacion, limiteValidacion);

                // Verificar si supera el umbral de error
                if (tamanoMuestra > estimacion * umbralErrorEstimacion) {
                    log.error("âŒ ERROR DE ESTIMACIÃ“N DETECTADO: {}x mÃ¡s registros de lo estimado",
                            tamanoMuestra / Math.max(estimacion, 1));
                    log.info("ğŸ”„ Cambiando automÃ¡ticamente a estrategia CRUDO (streaming)");

                    // Actualizar estimaciÃ³n en base de datos para futuras ejecuciones
                    actualizarEstimacionQuery(info, tamanoMuestra * 2);

                    // Cambiar a estrategia segura
                    ejecutarQueryConsolidableCrudo(repo, filtros, nombreQuery, provincia, contexto, info);
                    return;
                }

                // Si estÃ¡ dentro del umbral pero es grande, usar paginaciÃ³n
                log.info("ğŸ“„ Usando paginaciÃ³n para procesar todos los registros");
                ejecutarConPaginacionSegura(repo, filtros, nombreQuery, provincia, contexto, limiteValidacion);
                return;
            }

            // CASO 2: La muestra es completa (caben todos los datos)
            log.debug("âœ… Muestra completa: {} registros (dentro de lÃ­mite)", tamanoMuestra);

            // Verificar si la diferencia con la estimaciÃ³n es razonable
            if (estimacion > 0 && tamanoMuestra > estimacion * umbralErrorEstimacion) {
                log.warn("âš ï¸ Discrepancia con estimaciÃ³n: esperados={}, reales={}",
                        estimacion, tamanoMuestra);

                // Actualizar estimaciÃ³n para la prÃ³xima vez
                actualizarEstimacionQuery(info, tamanoMuestra);
            }

            // ===== PROCESAMIENTO NORMAL =====

            if (tamanoMuestra == 0) {
                log.debug("ğŸ“­ Query no retornÃ³ resultados para {}", provincia);
                return;
            }

            // Procesar resultados (ya estÃ¡n todos en memoria y son manejables)
            List<Map<String, Object>> resultadoInmutable = crearCopiasInmutables(muestraValidacion, provincia);
            contexto.agregarResultados(resultadoInmutable);
            actualizarContadores(provincia, tamanoMuestra);

            log.info("âœ… Query AGREGACION completada para {}: {} registros | Memoria: {:.1f}%",
                    provincia, tamanoMuestra, obtenerPorcentajeMemoriaUsada());

        } catch (OutOfMemoryError oom) {
            log.error("ğŸ’¥ OOM en query AGREGACION para {}. Esto NO deberÃ­a pasar con las validaciones.",
                    provincia);
            log.error("ğŸ”§ Considera reducir consolidacion.agregacion.limite-validacion en properties");

            // Intentar recuperaciÃ³n
            System.gc();
            throw new RuntimeException("OutOfMemoryError en consolidaciÃ³n AGREGACION", oom);

        } catch (Exception e) {
            log.error("âŒ Error en query AGREGACION {} para {}: {}",
                    nombreQuery, provincia, e.getMessage(), e);
        }
    }

    /**
     * ğŸ”„ Ejecuta query con paginaciÃ³n segura cuando el resultado es grande pero manejable.
     *
     * Usado cuando la validaciÃ³n detecta que hay mÃ¡s de 10K registros pero menos de 100K.
     */
    private void ejecutarConPaginacionSegura(
            InfraccionesRepositoryImpl repo,
            ParametrosFiltrosDTO filtros,
            String nombreQuery,
            String provincia,
            ContextoProcesamiento contexto,
            int tamanoPagina) {

        log.info("ğŸ“„ Iniciando paginaciÃ³n segura para {}: pÃ¡ginas de {} registros",
                provincia, tamanoPagina);

        int offset = 0;
        int totalProcesados = 0;
        int iteracion = 0;
        int maxIteraciones = limiteAbsoluto / tamanoPagina; // LÃ­mite de seguridad

        while (iteracion < maxIteraciones) {
            try {
                // Crear filtros para esta pÃ¡gina
                ParametrosFiltrosDTO filtrosPagina = filtros.toBuilder()
                        .limite(tamanoPagina)
                        .offset(offset)
                        .build();

                // Ejecutar query
                List<Map<String, Object>> pagina =
                        repo.ejecutarQueryConFiltros(nombreQuery, filtrosPagina);

                // Verificar si terminamos
                if (pagina == null || pagina.isEmpty()) {
                    log.debug("âœ… PaginaciÃ³n completada en iteraciÃ³n {}", iteracion);
                    break;
                }

                // Procesar pÃ¡gina
                List<Map<String, Object>> paginaInmutable = crearCopiasInmutables(pagina, provincia);
                contexto.agregarResultados(paginaInmutable);

                totalProcesados += pagina.size();
                offset += tamanoPagina;
                iteracion++;

                log.debug("ğŸ“„ PÃ¡gina {}: {} registros (total: {})", iteracion, pagina.size(), totalProcesados);

                // Si la pÃ¡gina no estÃ¡ llena, es la Ãºltima
                if (pagina.size() < tamanoPagina) {
                    break;
                }

                // Pausa si la memoria estÃ¡ alta
                if (esMemoriaAlta()) {
                    pausarSiNecesario();
                }

            } catch (Exception e) {
                log.error("âŒ Error en iteraciÃ³n {} de paginaciÃ³n: {}", iteracion, e.getMessage());
                break;
            }
        }

        if (iteracion >= maxIteraciones) {
            log.error("âš ï¸ LÃ­mite de iteraciones alcanzado ({}) para {}. Posible loop infinito evitado.",
                    maxIteraciones, provincia);
        }

        actualizarContadores(provincia, totalProcesados);
        log.info("âœ… PaginaciÃ³n segura completada para {}: {} registros en {} pÃ¡ginas",
                provincia, totalProcesados, iteracion);
    }

    /**
     * ğŸ“Š Actualiza la estimaciÃ³n de registros en QueryStorage.
     *
     * Cuando detectamos que la estimaciÃ³n estaba incorrecta,
     * actualizamos el registro en BD para mejorar futuras ejecuciones.
     */
    private void actualizarEstimacionQuery(QueryStorage info, int registrosReales) {
        try {
            log.info("ğŸ”„ Actualizando estimaciÃ³n para query {}: {} â†’ {}",
                    info.getCodigo(), info.getRegistrosEstimados(), registrosReales);

            info.setRegistrosEstimados(registrosReales);
            queryStorageRepository.save(info);

            log.debug("âœ… EstimaciÃ³n actualizada en base de datos");

        } catch (Exception e) {
            log.warn("âš ï¸ Error actualizando estimaciÃ³n para {}: {}",
                    info.getCodigo(), e.getMessage());
            // No fallar por esto, es solo metadata
        }
    }



/**
 * Ejecuta query consolidable CRUDO (mal diseÃ±ada).
 * La query retorna datos sin agregar y puede tener muchos registros.
 * Usa streaming para evitar OutOfMemoryError y consolida en memoria.
 *
 * Ejemplo: SELECT fecha, tipo, monto FROM infracciones WHERE...
 * Retorna: Miles de registros que deben ser consolidados
 *
 * @param repo Repositorio de la provincia
 * @param filtros Filtros aplicados
 * @param nombreQuery CÃ³digo de la query
 * @param provincia Nombre de la provincia
 * @param contexto Contexto de procesamiento
 * @param info InformaciÃ³n de la query
 */
private void ejecutarQueryConsolidableCrudo(
        InfraccionesRepositoryImpl repo,
        ParametrosFiltrosDTO filtros,
        String nombreQuery,
        String provincia,
        ContextoProcesamiento contexto,
        QueryStorage info) {

    try {
        log.info("Ejecutando query consolidable CRUDO con streaming para {}: {} registros estimados",
                 provincia, info.getRegistrosEstimados());

        // Configurar para usar streaming
        ParametrosFiltrosDTO filtrosStreaming = filtros.toBuilder()
                .limite(null)
                .offset(null)
                .build();

        // Buffer para procesar en chunks
        final int CHUNK_SIZE = 1000;
        final List<Map<String, Object>> buffer = new ArrayList<>(CHUNK_SIZE);
        final AtomicInteger totalProcesados = new AtomicInteger(0);
        final AtomicInteger chunksEnviados = new AtomicInteger(0);

        // Callback que se ejecuta por cada registro
        Consumer<Map<String, Object>> procesarRegistro = registro -> {
            buffer.add(registro);

            // Cuando el buffer se llena, procesarlo
            if (buffer.size() >= CHUNK_SIZE) {
                procesarChunk(buffer, provincia, contexto, totalProcesados, chunksEnviados);
            }
        };

        // Ejecutar query con streaming
        repo.ejecutarQueryConStreaming(nombreQuery, filtrosStreaming, procesarRegistro);

        // Procesar registros restantes en el buffer
        if (!buffer.isEmpty()) {
            procesarChunk(buffer, provincia, contexto, totalProcesados, chunksEnviados);
        }

        // Actualizar contador global
        actualizarContadores(provincia, totalProcesados.get());

        log.info(" Query consolidable CRUDO completada para {}: {} registros en {} chunks | Memoria: {:.1f}%",
                 provincia,
                 totalProcesados.get(),
                 chunksEnviados.get(),
                 obtenerPorcentajeMemoriaUsada());

    } catch (Exception e) {
        log.error(" Error en query consolidable CRUDO para {}: {}", provincia, e.getMessage(), e);
    }
}

/**
 * Procesa un chunk de registros y lo envÃ­a al contexto.
 * Libera memoria despuÃ©s de procesar.
 *
 * @param buffer Buffer con registros a procesar
 * @param provincia Nombre de la provincia
 * @param contexto Contexto de procesamiento
 * @param totalProcesados Contador total de registros procesados
 * @param chunksEnviados Contador de chunks enviados
 */
private void procesarChunk(
        List<Map<String, Object>> buffer,
        String provincia,
        ContextoProcesamiento contexto,
        AtomicInteger totalProcesados,
        AtomicInteger chunksEnviados) {

    // SOLO procesar si el buffer NO estÃ¡ vacÃ­o
    if(!buffer.isEmpty()){

        // Crear copia inmutable del chunk
        List<Map<String, Object>> chunkInmutable = crearCopiasInmutables(buffer, provincia);

        // Enviar al contexto
        contexto.agregarResultados(chunkInmutable);

        // Actualizar contadores
        int procesados = buffer.size();
        totalProcesados.addAndGet(procesados);
        chunksEnviados.incrementAndGet();

        // Log cada 10 chunks (10,000 registros)
        if (chunksEnviados.get() % 10 == 0) {
            log.debug("Provincia {}: {} registros procesados en {} chunks | Memoria: {:.1f}%",
                      provincia,
                      totalProcesados.get(),
                      chunksEnviados.get(),
                      obtenerPorcentajeMemoriaUsada());
        }

        // Vaciar buffer para liberar memoria
        buffer.clear();
    }

    // Pausa si memoria alta
    if (esMemoriaAlta()) {
        pausarSiNecesario();
    }
}

    /**
     * ğŸ”„ Ejecuta query paginada usando ROW_NUMBER.
     * CORREGIDO: Actualiza lastId correctamente entre iteraciones.
     */
    /**
     * ğŸ”„ Ejecuta query paginada usando OFFSET.
     * CORREGIDO: Usa OFFSET en lugar de ROW_NUMBER para consolidadas.
     */
    private void ejecutarQueryPaginada(
            InfraccionesRepositoryImpl repo,
            ParametrosFiltrosDTO filtros,
            String nombreQuery,
            String provincia,
            ContextoProcesamiento contexto) {

        String provinciaRepo = repo.getProvincia();
        int procesados = 0;
        int iteracion = 0;
        final int batchSize = 10000;  // âœ… LÃ­mite alto para consolidadas
        int offset = 0;  // âœ… Usar OFFSET en lugar de lastId

        Integer estimacion = obtenerEstimacionProvincia(nombreQuery, provinciaRepo);

        log.info("ğŸ”„ {} - Iniciando paginaciÃ³n OFFSET (estimado: {} registros)",
                provinciaRepo, estimacion != null ? estimacion : "desconocido");

        while (true) {
            try {
                // âœ… Log ANTES
                log.info("ğŸ”¹ {} - IteraciÃ³n {}: OFFSET={}, procesados: {}/{}",
                        provinciaRepo, iteracion, offset, procesados,
                        estimacion != null ? estimacion : "?");

                long inicioIteracion = System.currentTimeMillis();

                // âœ… Crear filtros con OFFSET
                ParametrosFiltrosDTO filtrosLote = filtros.toBuilder()
                        .limite(batchSize)
                        .offset(offset)      // âœ… CAMBIO: Usar OFFSET
                        .lastId(null)        // âœ… CAMBIO: No usar lastId
                        .lastSerieEquipo(null)
                        .lastLugar(null)
                        .lastKeysetConsolidacion(null)
                        .build();

                // Ejecutar query
                List<Map<String, Object>> lote = repo.ejecutarQueryConFiltros(nombreQuery, filtrosLote);

                long duracionIteracion = System.currentTimeMillis() - inicioIteracion;

                // âœ… Log DESPUÃ‰S
                log.info("âœ… {} - IteraciÃ³n {}: Recibidos {} registros en {}ms",
                        provinciaRepo, iteracion,
                        lote != null ? lote.size() : 0,
                        duracionIteracion);

                // Verificar si hay datos
                if (lote == null || lote.isEmpty()) {
                    log.info("ğŸ {} - Fin de datos en iteraciÃ³n {}", provinciaRepo, iteracion);
                    break;
                }

                // âœ… CAMBIO: Ya no necesitas extraer lastId

                // Procesar resultados (sin incluir row_id en resultados finales)
                List<Map<String, Object>> loteInmutable = crearCopiasInmutablesLimpio(lote, provinciaRepo);
                contexto.agregarResultados(loteInmutable);

                actualizarContadores(provinciaRepo,lote.size());

                // Actualizar contadores
                procesados += lote.size();
                offset += batchSize;  // âœ… CAMBIO: Incrementar offset en lugar de lastId
                iteracion++;

                // âœ… Log de progreso
                if (estimacion != null && estimacion > 0) {
                    double progreso = (double) procesados / estimacion * 100;
                    log.info("ğŸ“Š {} - Progreso: {}/{} registros ({:.1f}%) en {} iteraciones",
                            provinciaRepo, procesados, estimacion, progreso, iteracion);
                }

                actualizarContadores(provinciaRepo,lote.size());

                // âœ… CondiciÃ³n de salida: lote incompleto
                if (lote.size() < batchSize) {
                    log.info("ğŸ {} - Ãšltima pÃ¡gina (lote incompleto: {})",
                            provinciaRepo, lote.size());
                    break;
                }

                // LÃ­mite de seguridad
                if (iteracion >= 100) {
                    log.warn("âš ï¸ {} - LÃ­mite de iteraciones alcanzado", provinciaRepo);
                    break;
                }

                if (esMemoriaAlta()) {
                    pausarSiNecesario();
                }

            } catch (Exception e) {
                log.error("âŒ {} - Error en iteraciÃ³n {}: {}",
                        provinciaRepo, iteracion, e.getMessage(), e);
                break;
            }
        }

        log.info("âœ… {} - PaginaciÃ³n completada: {} registros en {} iteraciones | Memoria: {:.1f}%",
                provinciaRepo, procesados, iteracion, obtenerPorcentajeMemoriaUsada());

        actualizarContadores(provinciaRepo, procesados);
    }



    /**
     * Convierte un Object a Integer de forma segura.
     */
    private Integer convertirAInteger(Object valor) {
        if (valor instanceof Integer) {
            return (Integer) valor;
        } else if (valor instanceof Long) {
            return ((Long) valor).intValue();
        } else if (valor instanceof BigDecimal) {
            return ((BigDecimal) valor).intValue();
        } else if (valor instanceof String) {
            return Integer.parseInt((String) valor);
        } else {
            throw new IllegalArgumentException("Tipo no soportado: " + valor.getClass());
        }
    }

    /**
     * Crea copias inmutables SIN incluir row_id (campo tÃ©cnico).
     *
     * @param registros Lista de registros
     * @param provincia Nombre de la provincia
     * @return Lista de copias limpias
     */
    private List<Map<String, Object>> crearCopiasInmutablesLimpio(
            List<Map<String, Object>> registros,
            String provincia) {

        return registros.stream()
                .map(registro -> {
                    Map<String, Object> copia = new HashMap<>();

                    // Copiar todos los campos EXCEPTO row_id
                    registro.entrySet().stream()
                            .filter(e -> !"row_id".equals(e.getKey()))  // âœ… Excluir row_id
                            .filter(e -> !"provincia".equals(e.getKey()))
                            .forEach(e -> copia.put(e.getKey(), e.getValue()));

                    // Agregar provincia
                    copia.put("provincia", provincia);

                    return copia;
                })
                .collect(Collectors.toList());
    }

    /**
     * Obtiene estimaciÃ³n de registros para una provincia.
     */
    private Integer obtenerEstimacionProvincia(String nombreQuery, String provincia) {
        try {
            return queryRegistryService.buscarQuery(nombreQuery)
                    .map(QueryStorage::getRegistrosEstimados)
                    .orElse(null);
        } catch (Exception e) {
            return null;
        }
    }

    /**
     * Obtiene el Ãºltimo ID del lote actual
     */
    @Deprecated
    private Integer obtenerUltimoIdDelLote(List<Map<String, Object>> lote) {
        if (lote == null || lote.isEmpty()) {
            return null;
        }

        Map<String, Object> ultimoRegistro = lote.get(lote.size() - 1);

        // Buscar campo ID con diferentes nombres posibles
        String[] posiblesCamposId = {"id", "infraccion_id", "registro_id", "consecutivo"};

        for (String campo : posiblesCamposId) {
            Object valor = ultimoRegistro.get(campo);
            if (valor instanceof Integer) {
                return (Integer) valor;
            } else if (valor instanceof Long) {
                return ((Long) valor).intValue();
            } else if (valor instanceof String) {
                try {
                    return Integer.parseInt((String) valor);
                } catch (NumberFormatException e) {
                    // Continuar con siguiente campo
                }
            }
        }

        log.warn("âš ï¸ No se encontrÃ³ campo ID vÃ¡lido en el Ãºltimo registro. Campos disponibles: {}",
                ultimoRegistro.keySet());
        return null;
    }


    private List<Map<String, Object>> crearCopiasInmutables(List<Map<String, Object>> registros, String provincia) {
        return registros.stream()
                .map(registro -> {
                    Map<String, Object> copia = new HashMap<>();
                    registro.entrySet().stream()
                            .filter(e -> !"provincia".equals(e.getKey()))
                            .forEach(e -> copia.put(e.getKey(), e.getValue()));
                    copia.put("provincia", provincia);
                    return copia;
                })
                .collect(Collectors.toList());
    }

    private void actualizarContadores(String provincia, int cantidad) {
        // âœ… SUMAR al contador de la provincia (no reemplazar)
        contadoresPorProvincia.merge(provincia, cantidad, Integer::sum);

        // âœ… SUMAR al contador global
        totalRegistrosGlobales.addAndGet(cantidad);

        log.debug("ğŸ“Š Contadores actualizados - {}: +{} â†’ Total provincia: {}, Total global: {}",
                provincia,
                cantidad,
                contadoresPorProvincia.get(provincia),
                totalRegistrosGlobales.get());
    }

    /**
     * MÃ‰TODO CORREGIDO: Guarda lastKey detectando el tipo correcto
     *
     * PROBLEMA ANTERIOR:
     * - AsumÃ­a que lastKey[0] siempre era Integer
     * - Queries de consolidaciÃ³n NO tienen campo 'id'
     *
     * SOLUCIÃ“N:
     * - Guardar los valores tal como vienen
     * - NO asumir tipos en guardarLastKey
     * - Validar tipos en crearFiltrosParaLoteSiguiente
     */
    private void guardarLastKey(List<Map<String, Object>> lote, String provincia) {
        if (lote == null || lote.isEmpty()) {
            return;
        }

        try {
            Map<String, Object> ultimo = lote.get(lote.size() - 1);

            // CASO 1: Query estÃ¡ndar con campo 'id'
            if (ultimo.containsKey("id") && ultimo.get("id") != null) {
                Object id = ultimo.get("id");

                lastKeyPerProvince.put(provincia, new Object[] {
                        id,
                        ultimo.get("serie_equipo"),
                        ultimo.get("lugar")
                });

                log.debug("ğŸ”‘ Keyset estÃ¡ndar guardado para {}: id={} (tipo: {})",
                        provincia, id, id.getClass().getSimpleName());
            }
            // CASO 2: Query de consolidaciÃ³n SIN campo 'id'
            else {
                // Tomar los primeros 3 campos disponibles (sin asumir tipos)
                List<Object> keyValues = new ArrayList<>();
                int count = 0;

                for (Map.Entry<String, Object> entry : ultimo.entrySet()) {
                    if (entry.getValue() != null && count < 3) {
                        keyValues.add(entry.getValue());
                        count++;
                    }
                }

                if (!keyValues.isEmpty()) {
                    lastKeyPerProvince.put(provincia, keyValues.toArray());

                    log.debug("ğŸ”‘ Keyset consolidaciÃ³n guardado para {}: {} campos (tipos: {})",
                            provincia,
                            keyValues.size(),
                            keyValues.stream()
                                    .map(v -> v.getClass().getSimpleName())
                                    .collect(Collectors.joining(", ")));
                }
            }
        } catch (Exception e) {
            log.warn("âš ï¸ Error guardando lastKey para {}: {}", provincia, e.getMessage());
        }
    }

   private void logHeartbeat(int totalRepositorios) {
    long ahora = System.currentTimeMillis();
    long ultimo = ultimoHeartbeat.get();

    if (ahora - ultimo > HEARTBEAT_INTERVAL_MS) {
        // Actualizar sin condiciÃ³n de carrera
        ultimoHeartbeat.set(ahora);
        log.info("Heartbeat - {}s | {} registros | Memoria: {:.1f}%",
                (ahora - tiempoInicioGlobal) / 1000,
                totalRegistrosGlobales.get(),
                obtenerPorcentajeMemoriaUsada());
    }
}

    private double obtenerPorcentajeMemoriaUsada() {
        Runtime runtime = Runtime.getRuntime();
        return (double) (runtime.totalMemory() - runtime.freeMemory()) / runtime.maxMemory() * 100;
    }

    private boolean esMemoriaCritica() {
        Runtime runtime = Runtime.getRuntime();
        return ((double) (runtime.totalMemory() - runtime.freeMemory())
                / runtime.maxMemory()) > memoryCriticalThreshold;
    }

    private boolean esMemoriaAlta() {
        Runtime runtime = Runtime.getRuntime();
        return ((double) (runtime.totalMemory() - runtime.freeMemory()) / runtime.maxMemory()) > 0.70;
    }

    private void pausarSiNecesario() {
        if (esMemoriaAlta()) {
            try {
                Thread.sleep(50);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
    }

    private int calcularTamanoLoteOptimo(ParametrosFiltrosDTO filtros) {
        int batchSizeBase = filtros.getLimiteEfectivo();
        if (batchSizeBase < 1000) {
            batchSizeBase = defaultBatchSize;
        }

        Runtime runtime = Runtime.getRuntime();
        long memoriaLibre = runtime.maxMemory() - (runtime.totalMemory() - runtime.freeMemory());
        double porcentajeLibre = (double) memoriaLibre / runtime.maxMemory();

        if (porcentajeLibre < 0.20) {
            return Math.max(1000, batchSizeBase / 4);
        } else if (porcentajeLibre < 0.30) {
            return Math.max(2000, batchSizeBase / 2);
        }
        return Math.min(batchSizeBase, 10000);
    }

    /**
     * MÃ‰TODO CORREGIDO: crearFiltrosParaLote
     *
     * CAMBIOS:
     * 1. Primera iteraciÃ³n YA usa lÃ­mite razonable (no Integer.MAX_VALUE)
     * 2. Keyset se activa desde la SEGUNDA iteraciÃ³n
     * 3. NUNCA usa offset (solo keyset)
     */
    private ParametrosFiltrosDTO crearFiltrosParaLote(
            ParametrosFiltrosDTO filtrosOriginales,
            int batchSize,
            int offset,
            String provincia) {

        // PRIMERA ITERACIÃ“N: offset=0, sin keyset aÃºn
        if (offset == 0 || !lastKeyPerProvince.containsKey(provincia)) {
            log.debug("ğŸ”¹ Primera iteraciÃ³n para {}: limite={}, keyset=INACTIVO", provincia, batchSize);

            return filtrosOriginales.toBuilder()
                    .limite(batchSize)  // CRÃTICO: Usar lÃ­mite razonable
                    .offset(null)       // NUNCA usar offset
                    .lastId(null)
                    .lastSerieEquipo(null)
                    .lastLugar(null)
                    .lastKeysetConsolidacion(null)
                    .build();
        }

        // ITERACIONES SIGUIENTES: usar keyset
        Object[] lastKey = lastKeyPerProvince.get(provincia);

        // Detectar tipo de keyset
        if (esKeysetEstandar(lastKey)) {
            // Keyset estÃ¡ndar (id, serie_equipo, lugar)
            log.debug("ğŸ”‘ Keyset estÃ¡ndar para {}: id={}", provincia, lastKey[0]);

            return filtrosOriginales.toBuilder()
                    .limite(batchSize)
                    .offset(null)  // NUNCA usar offset con keyset
                    .lastId((Integer) lastKey[0])
                    .lastSerieEquipo(lastKey.length > 1 ? (String) lastKey[1] : null)
                    .lastLugar(lastKey.length > 2 ? (String) lastKey[2] : null)
                    .build();

        } else {
            // Keyset consolidaciÃ³n genÃ©rico
            Map<String, Object> keysetMap = construirKeysetMap(lastKey);

            log.debug("ğŸ”‘ Keyset consolidaciÃ³n para {}: {} campos", provincia, keysetMap.size());

            return filtrosOriginales.toBuilder()
                    .limite(batchSize)
                    .offset(null)
                    .lastKeysetConsolidacion(keysetMap)
                    .build();
        }
    }

    /**
     * Detecta si es keyset estÃ¡ndar (con id numÃ©rico)
     */
    private boolean esKeysetEstandar(Object[] lastKey) {
        return lastKey != null
                && lastKey.length >= 1
                && lastKey[0] instanceof Integer;
    }

    /**
     * Construye mapa de keyset para queries de consolidaciÃ³n
     */
    private Map<String, Object> construirKeysetMap(Object[] lastKey) {
        Map<String, Object> keysetMap = new HashMap<>();

        for (int i = 0; i < Math.min(lastKey.length, 3); i++) {
            if (lastKey[i] != null) {
                keysetMap.put("campo_" + i, lastKey[i]);
            }
        }

        return keysetMap;
    }

}